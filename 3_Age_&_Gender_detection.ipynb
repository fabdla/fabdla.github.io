{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabdoulaye/fabdoulaye.github.io/blob/main/3_Age_%26_Gender_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOdisP2JMrxN"
      },
      "source": [
        "<center><img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/logo_datascientest.png\" style=\"height:150px;center\"></center>\n",
        "\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "<center><h1>Deep-Learning - Modules complémentaires</h1></center>\n",
        "<center><h2>Détection du genre et de l'age d'une personne avec son visage</h2></center>\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "\n",
        "\n",
        "Le but de cet exercice est de s'exercer à créer des modèles à plusieurs sorties.\n",
        "\n",
        " Nous allons travailler avec la base de données **```age_gender.csv```**. Cette base contient des images de visages, ainsi que le genre et l'âge de la personne en question.\n",
        "\n",
        " Notez que les images sont stockées dans le DataFrame sous forme de string facilement convertibles en tableau ```numpy``` de taille 48*48. Chaque élément du tableau représente la valeur du pixel de l'image (l'image est donc en noir et blanc).\n",
        "\n",
        "> La structure de l'exercice est la suivante :\n",
        ">> I - [Préparation du dataset](#preparation)\n",
        ">>\n",
        ">>\n",
        ">> II - [Classification du genre et prédiction de l'âge avec un unique modèle](#model)\n",
        ">>\n",
        ">>\n",
        ">> III - [Test en temps réel](#test)\n",
        "\n",
        "- Exécuter la cellule ci-dessous pour importer les modules nécessaires à l'exercice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GtZCCm25Fhh",
        "outputId": "7d22a37a-5a97-4fc8-f433-a131311c0c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-21 22:31:53--  https://assets-datascientest.s3-eu-west-1.amazonaws.com/datasets/age_gender.zip\n",
            "Resolving assets-datascientest.s3-eu-west-1.amazonaws.com (assets-datascientest.s3-eu-west-1.amazonaws.com)... 52.218.49.19, 3.5.67.101, 52.92.19.210, ...\n",
            "Connecting to assets-datascientest.s3-eu-west-1.amazonaws.com (assets-datascientest.s3-eu-west-1.amazonaws.com)|52.218.49.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 66099409 (63M) [application/zip]\n",
            "Saving to: ‘age_gender.zip’\n",
            "\n",
            "age_gender.zip      100%[===================>]  63.04M  21.0MB/s    in 3.0s    \n",
            "\n",
            "2023-06-21 22:31:56 (21.0 MB/s) - ‘age_gender.zip’ saved [66099409/66099409]\n",
            "\n",
            "Archive:  age_gender.zip\n",
            "  inflating: age_gender.csv          \n"
          ]
        }
      ],
      "source": [
        "!wget https://assets-datascientest.s3-eu-west-1.amazonaws.com/datasets/age_gender.zip\n",
        "!unzip age_gender.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9sL3jousL5o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwjU8YZWeUI8",
        "outputId": "557e81ee-3683-4996-ecd1-c67314a0327f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG_rYNvUccC4"
      },
      "source": [
        "# I - <a name=\"preparation\"></a> Préparation du dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n2eVFyLSjO-"
      },
      "source": [
        "- (a) Exécuter la cellule suivante pour importer le jeu de données dans un DataFrame ```df``` et convertir la colonne ```pixels``` en tableau ```numpy``` redimensionné."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGXQ79SccjZo"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('age_gender.csv', sep=';')\n",
        "df['pixels'] = df['pixels'].apply(lambda x : np.array(x.split()).astype(np.int16).reshape(48, 48, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f26y6EtjUsI7"
      },
      "source": [
        "- (b) Afficher la shape de ```df``` ainsi que ses 5 premières lignes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kzK7tF3XudTo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAv_kpkeg5d8"
      },
      "source": [
        "- (c) Exécuter les cellules suivantes pour créer un générateur personnalisé à notre problème.\n",
        "> - Nous sommes obligés de créer ce type de générateur pour des modèles à plusieurs sorties comme ici.\n",
        ">\n",
        ">\n",
        "> - Le générateur n'applique pas de transformation aux images, simplement un scaling.\n",
        ">\n",
        "> - Pas besoin de reshape les données, cette étape a déjà été faite lors de l'importation de ```df```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dqwd7Wm21RZ"
      },
      "outputs": [],
      "source": [
        "class DataGenerator():\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "\n",
        "    def generate_splits(self):\n",
        "        '''reproduction de la fonction train_test_split'''\n",
        "        permut = np.random.permutation(len(self.df))          # mélange des indices\n",
        "\n",
        "        # équivalent de data_without_test, data_test = train_test_split(data, test_size=0.2)\n",
        "        train_up_to = int(len(self.df)*0.8)\n",
        "        indices_without_test = permut[:train_up_to]\n",
        "        test_indices = permut[train_up_to:]\n",
        "\n",
        "        # équivalent de data_train, data_validation = train_test_split(data_without_test, test_size=0.2)\n",
        "        train_up_to = int(train_up_to*0.8)\n",
        "        train_indices = indices_without_test[:train_up_to]\n",
        "        valid_indices = indices_without_test[train_up_to:]\n",
        "\n",
        "        return train_indices, valid_indices, test_indices     # on retourne les indices\n",
        "\n",
        "\n",
        "    def generate_images(self, indices, is_training, batch_size=32):\n",
        "        '''utilisé pour générer des batchs avec des images lors de l'entraînement/test/validation de notre modèle Keras\n",
        "           par exemple, on aura \"indices=train_indices, is_training=True\" pour un générateur d'entraînement\n",
        "                                \"indices=test_indices, is_training=False\" pour un générateur de test'''\n",
        "        max_age = self.df['age'].max()                                           # max_age sert à scaler les ages entre 0 et 1\n",
        "        files, genders, ages = [], [], []                                        # on initialise des listes vides pour contenir ce que renverra le générateur\n",
        "        while True:\n",
        "            for i in indices:                                                    # on parcourt les indices de la liste prise en argument\n",
        "                person = self.df.iloc[i]                                         # on repère la personne d'indice i\n",
        "\n",
        "                files.append((person['pixels']/255))                             # on ajoute l'image de la personne d'indice i(pixels scalés entre 0 et 1)\n",
        "                genders.append(person['gender'])                                 # on ajoute le genre de la personne d'indice i à la liste \"genders\"\n",
        "                ages.append(person['age']/max_age)                               # on ajoute l'age scalé de la personne d'indice i\n",
        "\n",
        "                if len(files) >= batch_size:                                     # dès qu'on a atteind la taille de batch souhaitée\n",
        "                    yield np.array(files), [np.array(genders), np.array(ages)]   # on renvoie les données\n",
        "                    # assurez-vous de vous souvenir de l'ordre des sorties car nous devrons définir notre modèle en conséquence\n",
        "                    files, genders, ages = [], [], []                            # on réinitialise les listes\n",
        "            # pour les prédictions, il faut s'arrêter après avoir parcouru toutes les données une fois\n",
        "            if not is_training:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsgsv9zk8zRK"
      },
      "outputs": [],
      "source": [
        "data_generator = DataGenerator(df)\n",
        "train_indices, valid_indices, test_indices = data_generator.generate_splits()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L51jVOn48zT9"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "training_data = data_generator.generate_images(train_indices, is_training=True, batch_size=batch_size)\n",
        "valid_data = data_generator.generate_images(valid_indices, is_training=True, batch_size=batch_size)\n",
        "test_data = data_generator.generate_images(test_indices, is_training=False, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P5BqRQftYDU"
      },
      "source": [
        "# II - <a name=\"model\"></a> Classification du genre et prédiction de l'âge avec un unique modèle\n",
        "\n",
        "Voici un template qui vous aidera à créer un modèle à plusieurs sorties :\n",
        "\n",
        "```py\n",
        "class MultiOutputModel():\n",
        "    def hidden_layers(self, inputs):\n",
        "        x = Conv2D(...)(inputs)\n",
        "        x = MaxPooling2D(...)(x)\n",
        "        ...\n",
        "        x = Dropout(...)(x)\n",
        "        return x\n",
        "    def branch_1(self, inputs):\n",
        "        x = self.hidden_layers(inputs)\n",
        "        x = ...(x)\n",
        "        ...\n",
        "        x = Dense(units=..., activation=..., name='output_1')(x)\n",
        "        return x\n",
        "    def branch_2(self, inputs):\n",
        "        x = self.hidden_layers(inputs)\n",
        "        x = ...(x)\n",
        "        ...\n",
        "        x = Dense(units=..., activation=..., name='output_2')(x)\n",
        "        return x\n",
        "    def create_model(self, input_shape):\n",
        "        inputs = Input(shape=input_shape)\n",
        "        branch_1 = self.branch_1(inputs)\n",
        "        branch_2 = self.branch_2(inputs)\n",
        "        model = Model(inputs=inputs, outputs=[branch_1, branch_2])\n",
        "        return model\n",
        "        \n",
        "model = MultiOutputModel().create_model(input_shape)\n",
        "\n",
        "loss = {'output_1': '...', 'output_2': '...'}\n",
        "metrics = {'output_1': '...', 'output_2': '...'}\n",
        "model.compile(optimizer='...', loss=loss, metrics=metrics)\n",
        "```\n",
        "\n",
        "- (a) Instancier un réseau de neurones à deux sorties (```gender_output``` et ```age_output```) de l'architecture de votre choix.\n",
        "> - Attention aux dernières couches de vos branches, il y a une classification et une régression à faire.\n",
        "\n",
        "- (b) Compiler le modèle avec des fonctions de perte et des métriques appropriées.\n",
        "\n",
        "- (c) Entraîner le modèle avec les générateurs d'entraînement et de validation définis précédemment. On pourra également définir des callbacks.\n",
        "\n",
        "- (d) Evaluer le modèle avec le générateur de test défini précédemment.\n",
        "\n",
        "- (e) Effectuer une prédiction à partir des données de test.\n",
        "\n",
        "- (f) Afficher des prédictions avec la fonction ```imshow```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao_fA_gFugW5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNqr6Qkptoe4"
      },
      "source": [
        "# III - <a name=\"test\"></a> Test en temps réel\n",
        "\n",
        "- (a) Lancer les cellules suivantes pour tester votre modèle en direct sur votre webcam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS3cdTFYtujy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX_leQvatumS"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "  return img\n",
        "\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "  return bbox_bytes\n",
        "\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML =\n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lOluAGxetupp",
        "outputId": "6c62397d-8df1-4d92-b788-655b628e074e"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "video_stream()\n",
        "label_html = 'Capturing...'\n",
        "bbox = ''\n",
        "count = 0\n",
        "gender_dict = {0 : 'Homme', 1 : 'Femme'}\n",
        "age_max = df['age'].max()\n",
        "\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "    for (x,y,w,h) in faces:\n",
        "      bbox_array = cv2.rectangle(bbox_array,(x,y),(x+w,y+h),(255,255,255),2)\n",
        "      face_img=gray[y:y+w,x:x+w]\n",
        "      resized=cv2.resize(face_img,(48,48))\n",
        "      reshaped=np.reshape(resized,(1, 48,48,1))\n",
        "      pred = model.predict(reshaped/255)\n",
        "      cv2.putText(bbox_array, gender_dict[pred[0][0][0].round()] + \" de \" + str(int(round(pred[1][0][0]*age_max))) + \" ans\", (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    bbox = bbox_bytes"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}